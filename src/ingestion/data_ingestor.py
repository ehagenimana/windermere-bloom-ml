{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6b4c29-04b2-4388-8f3a-f86243ae1baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import yaml\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class EAConfig:\n",
    "    base_url: str\n",
    "    page_size: int = 2500\n",
    "    timeout_s: int = 60\n",
    "    max_retries: int = 5\n",
    "    backoff_s: int = 2\n",
    "    user_agent: str = \"windermere-bloom-ml/0.1\"\n",
    "\n",
    "\n",
    "def _load_yaml(path: str) -> dict:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "\n",
    "class DataIngestor:\n",
    "    \"\"\"\n",
    "    Environment Agency Water Quality Archive ingestor.\n",
    "\n",
    "    Phase 1 goals:\n",
    "      - deterministic paginated pulls\n",
    "      - raw acquisition only (no modeling assumptions)\n",
    "      - ready for snapshotting + schema validation next\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, api_config_path: str = \"config/api.yaml\") -> None:\n",
    "        cfg = _load_yaml(api_config_path)\n",
    "        ea = cfg[\"ea_water_quality\"]\n",
    "        self.cfg = EAConfig(\n",
    "            base_url=ea[\"base_url\"],\n",
    "            page_size=int(ea.get(\"page_size\", 2500)),\n",
    "            timeout_s=int(ea.get(\"timeout_s\", 60)),\n",
    "            max_retries=int(ea.get(\"max_retries\", 5)),\n",
    "            backoff_s=int(ea.get(\"backoff_s\", 2)),\n",
    "            user_agent=str(ea.get(\"user_agent\", \"windermere-bloom-ml/0.1\")),\n",
    "        )\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\"User-Agent\": self.cfg.user_agent})\n",
    "\n",
    "    def _get_with_retries(self, url: str, params: Dict[str, Any]) -> List[dict]:\n",
    "        last_err: Optional[Exception] = None\n",
    "        for attempt in range(1, self.cfg.max_retries + 1):\n",
    "            try:\n",
    "                r = self.session.get(url, params=params, timeout=self.cfg.timeout_s)\n",
    "                r.raise_for_status()\n",
    "                data = r.json()\n",
    "                if not isinstance(data, list):\n",
    "                    raise ValueError(f\"Unexpected API response type: {type(data)}\")\n",
    "                return data\n",
    "            except Exception as e:\n",
    "                last_err = e\n",
    "                time.sleep(self.cfg.backoff_s * attempt)\n",
    "        raise RuntimeError(f\"EA API request failed after retries: {last_err}\") from last_err\n",
    "\n",
    "    def fetch_observations(\n",
    "        self,\n",
    "        determinand: int,\n",
    "        point_notation: Optional[str] = None,\n",
    "        start_date: Optional[str] = None,\n",
    "        end_date: Optional[str] = None,\n",
    "        compliance_only: bool = False,\n",
    "        limit_pages: Optional[int] = None,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Fetch observations with pagination.\n",
    "        Note: EA API supports skip/limit paging.\n",
    "\n",
    "        limit_pages: for smoke tests (e.g., 1-2 pages).\n",
    "        \"\"\"\n",
    "        params: Dict[str, Any] = {\n",
    "            \"determinand\": determinand,\n",
    "            \"limit\": self.cfg.page_size,\n",
    "            \"skip\": 0,\n",
    "            \"complianceOnly\": str(compliance_only).lower(),\n",
    "        }\n",
    "        if point_notation:\n",
    "            params[\"pointNotation\"] = point_notation\n",
    "        if start_date:\n",
    "            params[\"startDate\"] = start_date\n",
    "        if end_date:\n",
    "            params[\"endDate\"] = end_date\n",
    "\n",
    "        all_rows: List[dict] = []\n",
    "        page = 0\n",
    "\n",
    "        while True:\n",
    "            page += 1\n",
    "            rows = self._get_with_retries(self.cfg.base_url, params=params)\n",
    "            if not rows:\n",
    "                break\n",
    "            all_rows.extend(rows)\n",
    "            params[\"skip\"] += params[\"limit\"]\n",
    "\n",
    "            if limit_pages is not None and page >= limit_pages:\n",
    "                break\n",
    "\n",
    "        return pd.DataFrame(all_rows)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
